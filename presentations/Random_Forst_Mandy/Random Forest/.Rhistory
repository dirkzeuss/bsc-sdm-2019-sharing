install.packages("randomForest")
install.packages(c("covr", "e1071", "future", "igraph", "link2GI", "maptools", "rgdal", "roxygen2", "rversions", "webshot"))
setwd("~/bsc-sdm-2019-sharing/presentations/Random_Forst_Mandy/Random Forest")
#Datensatz zum Trainieren des Waldes
datasetTrain <- read.table("exampleDatasetTrain.csv", sep = ",", header=TRUE)
#zum Testen des Waldes mit neuen Daten
datasetTest <- read.table("exampleDatasetTest.csv", sep = ",", header=TRUE)
View(datasetTest)
View(datasetTrain)
str(datasetTrain)
#Zeige erste 6 Zeilen des Datensatzes
head(datasetTrain)
#### Random Forest ####
#install.packages("randomForest")
library("randomForest")
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
View(datasetTest)
View(myRF)
View(datasetTest)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myRF
set.seed(123) #sorgt daf?r, dass bei zwei unterschiedlichen Durchl?ufen, dieselben Ergebnisse auftauchen (anderer Seed, anderes Ergebnis)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myRF
set.seed(123) #sorgt daf?r, dass bei zwei unterschiedlichen Durchl?ufen, dieselben Ergebnisse auftauchen (anderer Seed, anderes Ergebnis)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=1000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myRF
set.seed(123) #sorgt daf?r, dass bei zwei unterschiedlichen Durchl?ufen, dieselben Ergebnisse auftauchen (anderer Seed, anderes Ergebnis)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=10000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myRF
set.seed(123) #sorgt daf?r, dass bei zwei unterschiedlichen Durchl?ufen, dieselben Ergebnisse auftauchen (anderer Seed, anderes Ergebnis)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=3,
ntree=1000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myRF
set.seed(123) #sorgt daf?r, dass bei zwei unterschiedlichen Durchl?ufen, dieselben Ergebnisse auftauchen (anderer Seed, anderes Ergebnis)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=5,
ntree=1000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myRF
set.seed(123) #sorgt daf?r, dass bei zwei unterschiedlichen Durchl?ufen, dieselben Ergebnisse auftauchen (anderer Seed, anderes Ergebnis)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myRF
summary(myRF)
#Baum Nr. 47 anschauen anschauen; Repr?sentation als Matrix
getTree(myRF, k=47, labelVar=TRUE) #wald ?bergeben myRF; k = Baumnummer 47; labelvar = Namen der Variablen, sonst Nummern
myRF2 <- grow(myRF, how.many=50)
grow(myRF, how.many=50)
myRF$oob.times
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=10000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myRF$oob.times
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=100000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
#Konfusionsmatrix mit den OOB-Daten
myRF$oob.times
set.seed(123) #sorgt daf?r, dass bei zwei unterschiedlichen Durchl?ufen, dieselben Ergebnisse auftauchen (anderer Seed, anderes Ergebnis)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
#Konfusionsmatrix mit den OOB-Daten
myRF$oob.times
mean(myRF$oob.times)
#Konfusionsmatrix mit den OOB-Daten
myRF$oob.times
View(datasetTest)
mean(myRF$oob.times)
#OOB-Fehlersch?tzung auslesen
myRF$err.rate
mean(myRF$oob.times)
#OOB-Fehlersch?tzung auslesen
myRF$err.rate
plot(myRF$err.rate[,1], type="l")
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=10000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
plot(myRF$err.rate[,1], type="l")
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=100000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
plot(myRF$err.rate[,1], type="l")
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=1000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
plot(myRF$err.rate[,1], type="l")
plot(myRF$err.rate[,1], type="l")
datasetTrain$ergebnis
#### Vorhersage ####
#1. Beobachtungen durch den Wald schleusen
#Berechnen des Wiedereinsetzungsfehlers
wahleKlasseTrain <- datasetTrain$ergebnis #Beobachtungen auslesen und in variable speichern
wahleKlasseTrain
vorhersage1 <- predict(myRF, newdata=datasetTrain) #predict-Befehl zur Vorhersage, mit den Beobachtungen
vorhersage1 # ergebnis der Vorhersage
table(wahleKlasseTrain,vorhersage1) #perfektes Ergebnis - perfekte Vorhersage
wahleKlasseTrain
vorhersage1
table(wahleKlasseTrain,vorhersage1) #perfektes Ergebnis - perfekte Vorhersage
#2. 100 neue Beobachtungen - Vorhersage
#Berechnung des Generalisierungsfehlers
wahleKlasseTest <- datasetTest$ergebnis
wahleKlasseTest
vorhersage2 <- predict(myRF, newdata=datasetTest)
vorhersage2
tab <- table(wahleKlasseTest,vorhersage2) #speichern der Matrix in Tabelle, Vorhersage nicht mehr perfekt
tab
#Accuracy; Anteil aller M?nner, f?r die eine korrekte Vorhersage get?tigt wurde; Zugriff auf Erfolg/Erfolg + Korb/Korb / Anzahl der Beobachtungen (100)
(tab[1,1]+tab[2,2])/length(wahleKlasseTest) # in xx% der F?lle korrekte Vorhersage
tab[1,1]
tab <- table(wahleKlasseTest,vorhersage2) #speichern der Matrix in Tabelle, Vorhersage nicht mehr perfekt
tab
View(datasetTest)
#Variablenwichtigkeit
imp <- varImpPlot(myRF) #variable importance plot - Ranking der Variablenwichtigkeit in zwei Verfahren; oben wichtig, unten unwichtig; "mittlere verlorene Votes"
imp
#Wie oft wurde welche Variable verwendet
varUsed(myRF, by.tree=FALSE, count=TRUE)
imp
#Variablenwichtigkeit
imp <- varImpPlot(myRF) #variable importance plot - Ranking der Variablenwichtigkeit in zwei Verfahren; oben wichtig, unten unwichtig; "mittlere verlorene Votes"
imp
set.seed(123) #sorgt daf?r, dass bei zwei unterschiedlichen Durchl?ufen, dieselben Ergebnisse auftauchen (anderer Seed, anderes Ergebnis)
myRF <- randomForest(ergebnis ~ ., data=datasetTrain, importance=TRUE, mtry=2,
ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
#Variablenwichtigkeit
imp <- varImpPlot(myRF) #variable importance plot - Ranking der Variablenwichtigkeit in zwei Verfahren; oben wichtig, unten unwichtig; "mittlere verlorene Votes"
imp
importance(myRF)
#Wie oft wurde welche Variable verwendet
varUsed(myRF, by.tree=FALSE, count=TRUE)
head(datasetTrain) #zeige variablen noch mal
#### Packages ####
library(maptools) #includes sp
library(dismo) #includes raster
library(randomForest)
# loading Predictor Files, used to predict a feature (Merkmal) variable
p_files <- list.files(path=paste(system.file(package="dismo"),'/ex', sep=''), pattern='grd', full.names=TRUE )
p_files
#p_files
predictors <- stack(p_files) #Raster-stacking 9 predictor files to one file
predictors
predictors # show Raster-Stack information
names(predictors) # show names of predictors
plot(predictors)
#library(maptools)
data(wrld_simpl) # load worldmap
# loading Data of Bradypus
file <- paste(system.file(package="dismo"), "/ex/bradypus.csv", sep="")
bradypus <- read.table(file, header=TRUE, sep=',')
bradypus
# first row is not necessary (Tierart), just lon and lat
bradypus <- bradypus[,-1]
# To speed up processing, restrict the predictions to a more restricted area (defined by a rectangular extent)
ext <- extent(-90, -32, -33, 23)
# Plotting, first layer of the RasterStack (Bio1)
plot(predictors, 1, ext=ext) #plot Bio1
plot(wrld_simpl, add=TRUE) #plot worldmap on top of Bio1, note the "add=TRUE" argument with plot
points(bradypus, col='blue') #add point on top of predictors and worldmap
#1 all presence-points
presence <- extract(predictors, bradypus) # Extracting presence values from rasters
tail(presence) # show last 6 entries
set.seed(0) #why zero?
background <- randomPoints(predictors, 500) # creating 500 random absence-points
absence <- extract(predictors, background) # Extracting absence values from rasters
pb <- c(rep(1, nrow(presence)), rep(0, nrow(absence)))
sdmdata <- data.frame(cbind(pb, rbind(presence, absence))) # putting pb and climate data into a single dataframe
sdmdata
tail(sdmdata)
summary(sdmdata)
# so that it won't be treated like any other numerical variable.
sdmdata[,'biome'] = as.factor(sdmdata[,'biome']) # set column 'biome' as factor, otherwise Regression
sdmdata[,'pb'] = as.factor(sdmdata[,'pb']) # set column 'pb' as factor, otherwise Regression
head(sdmdata) #show head of table, pb value 1 = presence
tail(sdmdata) #show tail of table, pb value 0 = absence
summary(sdmdata)
summary(sdmdata)
set.seed(123) #sorgt daf?r, dass bei zwei unterschiedlichen Durchl?ufen, dieselben Ergebnisse auftauchen (anderer Seed, anderes Ergebnis)
myForest<- randomForest(pb ~., data=sdmdata, importance=TRUE, mtry=3, ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myForest
#Baum Nr. 47 anschauen anschauen; Repr?sentation als Matrix
getTree(myForest, k=47, labelVar=TRUE) #wald ?bergeben myRF; k = Baumnummer 47; labelvar = Namen der Variablen, sonst Nummern
#Konfusionsmatrix mit den OOB-Daten
myForest$oob.times
mean(myForest$oob.times)
#OOB-Fehlersch?tzung auslesen
myForest$err.rate
plot(myForest$err.rate[,1], type="l")
#### Vorhersage ####
# 1. Beobachtungen durch den Wald schleusen
# Berechnen des Wiedereinsetzungsfehlers
klasseTrain <- sdmdata$pb #Beobachtungen auslesen und in variable speichern
vorhersage1 <- predict(myForest, newdata=sdmdata) #predict-Befehl zur Vorhersage, mit den Beobachtungen
vorhersage1 # Ergebnis der Vorhersage
tab <- table(klasseTrain,vorhersage1) #speichern der Matrix in Tabelle
tab # perfektes Ergebnis - perfekte Vorhersage ?
# Variablenwichtigkeit
imp <- varImpPlot(myForest) #variable importance plot - Ranking der Variablenwichtigkeit in zwei Verfahren; oben wichtig, unten unwichtig; "mittlere verlorene Votes"
imp
# Wie oft wurde welche Variable verwendet
varUsed(myForest, by.tree=FALSE, count=TRUE)
head(sdmdata) #zeige variablen noch mal
# Vorhersage plotten
r = raster(predictors, 1)
par(mfrow=c(1,2))
plot(!is.na(r), col=c('white', 'brown'), ext=ext ,legend=FALSE, main='Presence of Bradypus')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(bradypus, col='black') #add point on top of predictors and worldmap
# Vorhersage plotten
r = raster(predictors, 1)
par(mfrow=c(1,2))
plot(!is.na(r), col=c('white', 'brown'), ext=ext ,legend=FALSE, main='Presence of Bradypus')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(bradypus, col='black') #add point on top of predictors and worldmap
pr <- predict(predictors, myForest, ext=ext)
#par(mfrow=c(1,2))
plot(pr, col=c('brown', 'black'), legend=FALSE, main='Random Forest, Classification')
plot(wrld_simpl, add=TRUE, border='dark grey')
plot(!is.na(r), col=c('white', 'brown'), ext=ext ,legend=FALSE, main='Presence of Bradypus')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(bradypus, col='black') #add point on top of predictors and worldmap
#par(mfrow=c(1,2))
plot(pr, col=c('brown', 'black'), legend=FALSE, main='Random Forest, Classification')
plot(wrld_simpl, add=TRUE, border='dark grey')
# Variablenwichtigkeit
imp <- varImpPlot(myForest) #variable importance plot - Ranking der Variablenwichtigkeit in zwei Verfahren; oben wichtig, unten unwichtig; "mittlere verlorene Votes"
# Wie oft wurde welche Variable verwendet
varUsed(myForest, by.tree=FALSE, count=TRUE)
head(sdmdata) #zeige variablen noch mal
#Baum Nr. 47 anschauen anschauen; Repr?sentation als Matrix
getTree(myForest, k=47, labelVar=TRUE) #wald ?bergeben myRF; k = Baumnummer 47; labelvar = Namen der Variablen, sonst Nummern
#Konfusionsmatrix mit den OOB-Daten
myForest$oob.times
mean(myForest$oob.times)
#OOB-Fehlersch?tzung auslesen
myForest$err.rate
plot(myForest$err.rate[,1], type="l")
myForest<- randomForest(pb ~., data=sdmdata, importance=TRUE, mtry=3, ntree=2000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
plot(myForest$err.rate[,1], type="l")
#Konfusionsmatrix mit den OOB-Daten
myForest$oob.times
myForest<- randomForest(pb ~., data=sdmdata, importance=TRUE, mtry=3, ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myForest
#Konfusionsmatrix mit den OOB-Daten
myForest$oob.times
#OOB-Fehlersch?tzung auslesen
myForest$err.rate
#### Vorhersage ####
# 1. Beobachtungen durch den Wald schleusen
# Berechnen des Wiedereinsetzungsfehlers
klasseTrain <- sdmdata$pb #Beobachtungen auslesen und in variable speichern
vorhersage1 <- predict(myForest, newdata=sdmdata) #predict-Befehl zur Vorhersage, mit den Beobachtungen
vorhersage1 # Ergebnis der Vorhersage
tab <- table(klasseTrain,vorhersage1) #speichern der Matrix in Tabelle
tab # perfektes Ergebnis - perfekte Vorhersage ?
myForest<- randomForest(pb ~., data=sdmdata, importance=TRUE, mtry=3, ntree=10000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myForest
vorhersage1 <- predict(myForest, newdata=sdmdata) #predict-Befehl zur Vorhersage, mit den Beobachtungen
vorhersage1 # Ergebnis der Vorhersage
tab <- table(klasseTrain,vorhersage1) #speichern der Matrix in Tabelle
tab # perfektes Ergebnis - perfekte Vorhersage ?
myForest<- randomForest(pb ~., data=sdmdata, importance=TRUE, mtry=3, ntree=100000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myForest
plot(myForest$err.rate[,1], type="l")
#### Vorhersage ####
# 1. Beobachtungen durch den Wald schleusen
# Berechnen des Wiedereinsetzungsfehlers
klasseTrain <- sdmdata$pb #Beobachtungen auslesen und in variable speichern
vorhersage1 <- predict(myForest, newdata=sdmdata) #predict-Befehl zur Vorhersage, mit den Beobachtungen
vorhersage1 # Ergebnis der Vorhersage
tab <- table(klasseTrain,vorhersage1) #speichern der Matrix in Tabelle
tab # perfektes Ergebnis - perfekte Vorhersage ?
myForest<- randomForest(pb ~., data=sdmdata, importance=TRUE, mtry=3, ntree=100, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myForest
#Konfusionsmatrix mit den OOB-Daten
myForest$oob.times
mean(myForest$oob.times)
#OOB-Fehlersch?tzung auslesen
myForest$err.rate
plot(myForest$err.rate[,1], type="l")
#### Vorhersage ####
# 1. Beobachtungen durch den Wald schleusen
# Berechnen des Wiedereinsetzungsfehlers
klasseTrain <- sdmdata$pb #Beobachtungen auslesen und in variable speichern
vorhersage1 <- predict(myForest, newdata=sdmdata) #predict-Befehl zur Vorhersage, mit den Beobachtungen
vorhersage1 # Ergebnis der Vorhersage
tab <- table(klasseTrain,vorhersage1) #speichern der Matrix in Tabelle
tab # perfektes Ergebnis - perfekte Vorhersage ?
#par(mfrow=c(1,2))
plot(pr, col=c('brown', 'black'), legend=FALSE, main='Random Forest, Classification')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(bradypus, col='black') #add point on top of predictors and worldmap
#par(mfrow=c(1,2))
plot(pr, col=c('brown', 'black'), legend=FALSE, main='Random Forest, Classification')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(bradypus, col='black') #add point on top of predictors and worldmap
#par(mfrow=c(1,2))
plot(pr, col=c('brown', 'black'), legend=FALSE, main='Random Forest, Classification')
plot(wrld_simpl, add=TRUE, border='dark grey')
pdf("test.pdf")
plot(pr, col=c('brown', 'black'), legend=FALSE, main='Random Forest, Classification')
points(bradypus, col='black') #add point on top of predictors and worldmap
dev.off()
pr <- raster::predict(predictors, myForest, ext=ext)
#par(mfrow=c(1,2))
plot(pr, col=c('brown', 'black'), legend=FALSE, main='Random Forest, Classification')
plot(wrld_simpl, add=TRUE, border='dark grey')
myForest<- randomForest(pb ~., data=sdmdata, importance=TRUE, mtry=3, ntree=100000, replace=TRUE, do.trace=TRUE, keep.forest=TRUE)
myForest
#Baum Nr. 47 anschauen anschauen; Repr?sentation als Matrix
getTree(myForest, k=47, labelVar=TRUE) #wald ?bergeben myRF; k = Baumnummer 47; labelvar = Namen der Variablen, sonst Nummern
#Spalte 1 = Wurzel von Baum k fragt, ob split var < split point ist; bedingung erf?llt, dann immer left daughter, bedingung nicht erf?llt right daughter
##Status 1 = innerer Knoten/Wurzel; -1 = Blatt (Ende)-> Vorhersage des Ergebnisses -> 0 oder 1
#### OOB-Daten ####
#gute Sch?tzung f?r Generalisierungsfehler
#Konfusionsmatrix mit den OOB-Daten
myForest$oob.times
#Stichprben-Nr. y wurde xx Mal nicht zur Erstellung von B?umen verwendet, .... , xx B?ume werden zu einem Teilwald verschmolzen -> erneute Vorhersage zur Absch?tzung, wie gut der Wald mit neuen Daten zurecht kommt
mean(myForest$oob.times)
#jede Stichprobe wurde zu xx Mal der B?ume nicht verwendet
#OOB-Fehlersch?tzung auslesen
myForest$err.rate
#Matrix mit n Beobachtungen - Zeile n = oob aus myForest, Prozensatz f?rs Vertun bei Presence | Absence
plot(myForest$err.rate[,1], type="l")
# x Zeile = B?ume, y = OOB-Fehler
# Entwicklung des OOB ?ber zunehmende Baumanzahl
# Grund: Wie viele B?ume soll ich erstellen innerhalb eines Waldes? Gro?e Schwankungen bei niedriger Baumanzahl, Einpendeln bei h?herer Baumzahl
#### Vorhersage ####
# 1. Beobachtungen durch den Wald schleusen
# Berechnen des Wiedereinsetzungsfehlers
klasseTrain <- sdmdata$pb #Beobachtungen auslesen und in variable speichern
#klasseTrain
vorhersage1 <- predict(myForest, newdata=sdmdata) #predict-Befehl zur Vorhersage, mit den Beobachtungen
vorhersage1 # Ergebnis der Vorhersage
tab <- table(klasseTrain,vorhersage1) #speichern der Matrix in Tabelle
tab # perfektes Ergebnis - perfekte Vorhersage ?
# 2. neue Beobachtungen - Vorhersage
# Berechnung des Generalisierungsfehlers
# nicht berechenbar, weil kein zweiter Datensatz vorhanden; m?glich bradypus datensatz am Anfang zu teilen und so zwei datens?tze zum vergleichen zu erstellen
# Wie Vorhersage machen? Trainingsdata does not match the testdata (pb fehlt)
# Accuracy; Anteil aller Objekte, f?r die eine korrekte Vorhersage get?tigt wurde; Zugriff auf Presence/Presence + Absence/Absence / Anzahl der Beobachtungen (100)
#(tab[1,1]+tab[2,2])/length(KlasseTest) # in xx% der F?lle korrekte Vorhersage
# Variablenwichtigkeit
imp <- varImpPlot(myForest) #variable importance plot - Ranking der Variablenwichtigkeit in zwei Verfahren; oben wichtig, unten unwichtig; "mittlere verlorene Votes"
imp
# Wie oft wurde welche Variable verwendet
varUsed(myForest, by.tree=FALSE, count=TRUE)
head(sdmdata) #zeige variablen noch mal
# Vorhersage plotten
r = raster(predictors, 1)
par(mfrow=c(1,2))
plot(!is.na(r), col=c('white', 'brown'), ext=ext ,legend=FALSE, main='Presence of Bradypus')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(bradypus, col='black') #add point on top of predictors and worldmap
pr <- raster::predict(predictors, myForest, ext=ext)
#par(mfrow=c(1,2))
plot(pr, col=c('brown', 'black'), legend=FALSE, main='Random Forest, Classification')
plot(wrld_simpl, add=TRUE, border='dark grey')
pdf("test2.pdf")
plot(pr, col=c('brown', 'black'), legend=FALSE, main='Random Forest, Classification')
points(bradypus, col='black') #add point on top of predictors and worldmap
dev.off()
